# Example: DRAFT Protocol + Ollama for local LLM-enhanced governance.
#
# Usage:
#   docker compose -f docker-compose.example.yml up
#
# This starts DRAFT with SSE transport on port 8420 and connects
# to a local Ollama instance for enhanced tier classification and
# embedding-based field assessment.
#
# Without Ollama: DRAFT still works using keyword heuristics.
# With Ollama: Semantic classification, embedding assessment, smart suggestions.

services:
  draft-protocol:
    build: .
    ports:
      - "8420:8420"
    environment:
      DRAFT_TRANSPORT: sse
      DRAFT_HOST: "0.0.0.0"
      DRAFT_PORT: "8420"
      DRAFT_LLM_PROVIDER: ollama
      DRAFT_LLM_MODEL: llama3.2:3b
      DRAFT_EMBED_MODEL: nomic-embed-text
      DRAFT_API_BASE: http://ollama:11434
    depends_on:
      ollama:
        condition: service_started
    volumes:
      - draft-data:/home/draft/.draft_protocol

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama-models:/root/.ollama

volumes:
  draft-data:
  ollama-models:
